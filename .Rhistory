doc<-xmlTreeParse(fileURL,useInternal= TRUE)
rootNode<-xmlroot(doc)
xmlName(rootNode)
xcds
library(XML)
library(RCurl)
fileURL<-"http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc<-xmlTreeParse(fileURL,useInternal= TRUE)
doc
doc
xmlRoot(doc)
library(XML)
library(RCurl)
fileURL<-"http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc<-xmlTreeParse(fileURL,useInternal= TRUE)
rootNode<-xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[[1]]
rootNode[[1]][[1]][[1]]
rootNode[[1]][[1]]
rootNode[[1]][[zipcode]]
rootNode[[1]][["zipcode"]]
xpathSApply(doc,"//zipcode",xmlValue)
xpathSApply(doc,"row[@zipcode="21231"]",xmlValue)
xpathSApply(doc,"row[@zipcode=21231]",xmlValue)
zipcodes<-xpathSApply(doc,"row[@zipcode=21231]",xmlValue)
zipcodes[zipcodes==21231]
zipcodes[zipcodes=="21231""]
zipcodes[zipcodes=="21231"]
zipcodes
xpathSApply(doc,"row[@zipcode=21231]",xmlValue)
thezippy<-xpathSApply(doc,"//zipcode",xmlValue)
thezippy(thezippy=="21231")
thezippy[thezippy=="21231"]
length(thezippy[thezippy=="21231"])
library(XML)
library(RCurl)
fileURL<-"http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc<-xmlTreeParse(fileURL,useInternal= TRUE)
rootNode<-xmlRoot(doc)
xmlName(rootNode)
thezippy<-xpathSApply(doc,"//zipcode",xmlValue)
length(thezippy[thezippy=="21231"])
?fread
?fread()
if (!file.exists("communitiesdata")){
dir.create("communitiesdata")
}
fileURL<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileURL,destfile = "./communitiesdata/rawcommunitiesdata.csv",method="auto")
datedownloaded<-date()
DT<-fread("./communitiesdata/rawcommunitiesdata.csv")
install.packages(fread)
install.packages("data.table")
if (!file.exists("communitiesdata")){
dir.create("communitiesdata")
}
fileURL<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileURL,destfile = "./communitiesdata/rawcommunitiesdata.csv",method="auto")
datedownloaded<-date()
DT<-fread("./communitiesdata/rawcommunitiesdata.csv")
fread()
library(data.table)
fread()
DT<-fread("./communitiesdata/rawcommunitiesdata.csv")
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(mean(DT$pwgtp15,by=DT$SEX))
?system.time
install.packages("rbenchmark")
?rbenchmark
library(rbenchmark)
rbenchmark(mean(DT$pwgtp15,by=DT$SEX))
rbenchmark::mean(DT$pwgtp15,by=DT$SEX)
system.time(mean(DT$pwgtp15,by=DT$SEX))
benchmark(mean(DT$pwgtp15,by=DT$SEX))
benchmark(mean(DT$pwgtp15,by=DT$SEX),replications = 100000)
benchmark(DT[,mean(pwgtp15),by=SEX],replications = 100000)
benchmark(DT[,mean(pwgtp15),by=SEX],replications = 100)
if (!file.exists("communitiesdata")){
dir.create("communitiesdata")
}
fileURL<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileURL,destfile = "./communitiesdata/rawcommunitiesdata.csv",method="auto")
datedownloaded<-date()
DT<-fread("./communitiesdata/rawcommunitiesdata.csv")
benchmark(DT[,mean(pwgtp15),by=SEX],replications = 100)
benchmark(mean(DT$pwgtp15,by=DT$SEX),replications = 100)
benchmark(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2],replications = 100)
benchmark(sapply(split(DT$pwgtp15,DT$SEX),mean),replications = 100)
benchmark(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15),replications = 100)
benchmark(tapply(DT$pwgtp15,DT$SEX,mean),replications = 100)
benchmark(DT[,mean(pwgtp15),by=SEX],replications = 100)
benchmark(mean(DT$pwgtp15,by=DT$SEX),replications = 100)
benchmark((rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]),replications = 100)
benchmark(sapply(split(DT$pwgtp15,DT$SEX),mean),replications = 100)
benchmark((mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15),replications = 100)
benchmark(tapply(DT$pwgtp15,DT$SEX,mean),replications = 100)
benchmark(DT[,mean(pwgtp15),by=SEX],replications = 100)
benchmark(mean(DT$pwgtp15,by=DT$SEX),replications = 100)
benchmark((rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]),replications = 100)
benchmark(sapply(split(DT$pwgtp15,DT$SEX),mean),replications = 100)
benchmark((mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15),replications = 100)
benchmark(tapply(DT$pwgtp15,DT$SEX,mean),replications = 100)
benchmark((rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]),replications = 100)
benchmark({rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]},replications = 100)
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
rowMeans(DT)[DT$SEX==1]
benchmark(DT[,mean(pwgtp15),by=SEX],replications = 1000)
benchmark(mean(DT$pwgtp15,by=DT$SEX),replications = 1000)
benchmark((rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]),replications = 1000)
benchmark(sapply(split(DT$pwgtp15,DT$SEX),mean),replications = 1000)
benchmark((mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15),replications = 1000)
benchmark(tapply(DT$pwgtp15,DT$SEX,mean),replications = 1000)
rowMeans(DT)[DT$SEX==1]
[DT$SEX==1]
DT$SEX==1
mean(DT$pwgtp15,by=DT$SEX)
tapply(DT$pwgtp15,DT$SEX,mean)
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
DT
mean(DT$pwgtp15,by=DT$SEX)
tapply(DT$pwgtp15,DT$SEX,mean)
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
DT[,$SEX]
DT[,DT$SEX]
column1<-DT[,DT$SEX]
column2<-DT[,DT$pwgtp15]
sapply(split(DT$pwgtp15,DT$SEX),mean)
benchmark(tapply(DT$pwgtp15,DT$SEX,mean),replications = 1000)
benchmark(sapply(split(DT$pwgtp15,DT$SEX),mean),replications = 1000)
DT[,mean(pwgtp15),by=SEX]
benchmark(tapply(DT$pwgtp15,DT$SEX,mean),replications = 1000)
benchmark(sapply(split(DT$pwgtp15,DT$SEX),mean),replications = 1000)
benchmark(DT[,mean(pwgtp15),by=SEX],replications = 1000)
benchmark(tapply(DT$pwgtp15,DT$SEX,mean),replications = 10000)
benchmark(sapply(split(DT$pwgtp15,DT$SEX),mean),replications = 10000)
benchmark(DT[,mean(pwgtp15),by=SEX],replications = 10000)
benchmark(sapply(split(DT$pwgtp15,DT$SEX),mean),replications = 50000)
benchmark(DT[,mean(pwgtp15),by=SEX],replications = 50000)
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
library(ggplot2)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
qplot(Wind, Ozone, data = airquality, geom = "smooth")
qplot(Wind, Ozone, data = airquality)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
install.packages("RGoogleAnalytics")
require(RGoogleAnalytics)
# Authorize the Google Analytics account
# This need not be executed in every session once the token object is created
# and saved
token <- Auth(client.id,client.secret)
# Save the token object for future sessions
save(token,file="./token_file")
# In future sessions it can be loaded by running load("./token_file")
ValidateToken(token)
# Build a list of all the Query Parameters
query.list <- Init(start.date = "2013-11-28",
end.date = "2013-12-04",
dimensions = "ga:date,ga:pagePath,ga:hour,ga:medium",
metrics = "ga:sessions,ga:pageviews",
max.results = 10000,
sort = "-ga:date",
table.id = "ga:33093633")
# Create the Query Builder object so that the query parameters are validated
ga.query <- QueryBuilder(query.list)
# Extract the data and store it in a data-frame
ga.data <- GetReportData(ga.query, token, split_daywise = T, delay = 5)
swirl()
library(swirl)
rm(list=ls())
swirl()
R.version.string
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
library(swirl)
swirl()
mydf<-read.csv(path2csv,stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran<-tbl_df(mydf)
rm('mydf')
cran
?select
select(cran,ip_id,package,country)
5:20
select(cran,r_arch:country)
select(cran,country:r_arch)
cran
select(cran,-time)
-5:20
-(5:20)
select(cran,-(X:size))
filter(cran,package=="swirl")
filter(cran,r_version=="3.1.1",country=="US")
?Comparison
filter(cran,r_version<="3.0.2",country=="IN")
filter(cran,country=="US"|country=="IN")
filter(cran,size>100500 & r_os=="linux-gnu")
filter(cran,size>100500,r_os=="linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran,r_version!=NA)
filter(cran,!is.na(r_version))
cran2<-select(cran,size:ip_id)
arrange(cran2,ip_id)
arrange(cran2,dec(ip_id)
)
arrange(cran2,desc(ip_id))
arrage(cran2,package,ip_id)
arrange(cran2,package,ip_id)
arrange(cran2,country,desc(r_version),ip_id)
cran3<-select(cran,ip_id,package,size)
cran3
mutate(cran3,size_mb=size/2^20)
mutate(cran3,size_mb=size/2^20,size_gb=size_mb/2^10)
mutate(cran3,correct_size=size-1000)
mutate(cran3,correct_size=size+1000)
summarize(cran,avg_bytes=mean(size))
library(dplyr)
cran<-tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package<-group_by(cran,package)
by_package
summarize(by_package,mean(size))
?n
?n_distinct
# Compute four values, in the following order, from
# the grouped data:
#
# 1. count = n()
# 2. unique = n_distinct(ip_id)
# 3. countries = n_distinct(country)
# 4. avg_bytes = mean(size)
#
# A few thing to be careful of:
#
# 1. Separate arguments by commas
# 2. Make sure you have a closing parenthesis
# 3. Check your spelling!
# 4. Store the result in pack_sum (for 'package summary')
#
# You should also take a look at ?n and ?n_distinct, so
# that you really understand what is going on.
pack_sum <- summarize(by_package,
count = n(),
unique = n_distinct(ip_id),
countries = n_distinct(country) ,
avg_bytes = mean(size) )
submit()
pack_sum
quantile(pack_sum$count,probs=0.99)
top_counts<-filter(pack_sum,count>679)
top_counts
View(top_counts)
top_counts_sorted<-arrange(top_counts,desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique,probs=0.99)
top_unique<-filter(pack_sum,unique>465)
Wiew(top_unique)
View(top_unique)
top_unique_sorted<-arrange(top_unique,desc(unique()))
top_unique_sorted<-arrange(top_unique,desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
# select() the following columns from cran. Keep in mind
# that when you're using the chaining operator, you don't
# need to specify the name of the data tbl in your call to
# select().
#
# 1. ip_id
# 2. country
# 3. package
# 4. size
#
# The call to print() at the end of the chain is optional,
# but necessary if you want your results printed to the
# console. Note that since there are no additional arguments
# to print(), you can leave off the parentheses after
# the function name. This is a convenient feature of the %>%
# operator.
cran %>%
select(ip_id,country,package,size) %>%
print
submit()
submit()
submit()
submit()
submit()
submit()
submit()
library(swirl)
rm(list=ls())
swirl()
library(tidyr)
students
?gather
gather(students,sex,count,-grade)
students2
gather(students2,sex_class,count,-grade)
res<-gather(students2,sex_class,count,-grade)
res
?separate
separate(res,sex_class,into=c("sex","class"))
submit()
students3
submit()
submit()
?gather
submit()
?spread
install.packages(knitr)
install.packages("knitr")
setwd("C:/Users/Aimilia/Desktop/DataScience/repdata-031")
install.packages(xtable)
install.packages("xtable")
title: "Reproducible Research: Peer Assessment 1"
output:
html_document:
keep_md: true
---
## Loading and preprocessing the data
Initial load of the .csv file that has to be located in the same folder.
Assign directly classes to the different variables as well as the string that represents the NA values.
```{r}
thedata<-read.csv("activity.csv",colClasses = c("integer","Date","integer"),na.strings = "NA",header=TRUE)
```
## What is mean total number of steps taken per day?
In order to remove the na's from the dataset, we will create a new dataset that will only inlcude the complete cases and will also calculate the total number of steps per day
```{r,message=F, warning=F}
library(dplyr)
stepsperday<-thedata%>%
filter(complete.cases(.))%>%
group_by(date)%>%
summarise(steps=sum(steps))
```
The following plot shows the frequency of total number of steps taken each day. A range of 3000 stpes was used in order to group the data in a way that will provide insightfull data.
```{r,message=F, warning=F}
library(ggplot2)
##qplot(steps, data=stepsperday, geom="histogram",binwidth=3000)
m<-ggplot(stepsperday,aes(x=steps))
m+geom_histogram(colour = "darkgreen", fill = "green",binwidth=3000)+
ylim(c(0, 20))+
stat_bin(binwidth=3000,geom="text", aes(label=..count..), vjust=-1.5)+
labs(x="Steps Per Day", y="No of days") +
scale_x_continuous(breaks=seq(0,24000,3000))
```
The mean of the total number of steps taken per day is: **mean =`r format(mean(stepsperday$steps),digits=2,nsmall=2)`** and the median is: **median= `r median(stepsperday$steps)`**.
## What is the average daily activity pattern?
Calculation of the average of steps per interval for all days as well as of the numbers of NAs per interval
and the number of total measurements per interval.
```{r}
stepsperintervalclean<-thedata%>%
filter(complete.cases(.))%>%
group_by(interval)%>%
summarise(steps=mean(steps))
```
And the time series plot that occurs is:
```{r}
m2<-ggplot(stepsperintervalclean,aes(x=interval,y=steps))
m2+geom_line(colour = "darkgreen")+
labs(x="Interval", y="Average steps per interval")
```
The most active internal of the day is **`r stepsperintervalclean[which.max(stepsperintervalclean$steps),1]`**
## Imputing missing values
The initial dataset has **`r sum(is.na(thedata$steps))` na values** where the number of steps were not measured.
In order to fill the values with NAs we will have first to check the number of missing values
per interval in comparison with the number of total measurements for each interval.
This way we will know if it will be wise to use the average steps from all the days for the specific interval.
```{r}
stepsperinterval<-thedata%>%
group_by(interval)%>%
summarise(average=mean(steps,na.rm=TRUE),NAs=sum(is.na(steps)),values=n())
summary(stepsperinterval$NAs/stepsperinterval$values)
```
stepsperintervalclean
stepsperinterval
merge(thedata,stepsperinterval,by=interval)
thedata
head(thedata)
merge(thedata,stepsperinterval,by=interval)
merge(thedata,stepsperinterval,by="interval")
head(merge(thedata,stepsperinterval,by="interval"),20)
head(thedata)
head(stepsperinterval)
head(stepsperinterval,20)
head(stepsperinterval,40)
hist(stepsperinterval$average)
mergeddata<-merge(thedata,stepsperinterval,by="interval")
mergeddata
if(is.na(mergeddata$interval)){}
head(mergeddata)
mergeddata[is.na(mergeddata$steps),]
mergeddata[is.na(mergeddata$steps),mergeddata$steps]<-mergeddata[is.na(mergeddata$steps),mergeddata$average]
mergeddata[is.na(mergeddata$steps),mergeddata$steps]<-mergeddata[is.na(mergeddata$steps),mergeddata$average]
mergeddata$steps[is.na(mergeddata$steps)] <- mergeddata$average[is.na(mergeddata$steps)])
mergeddata$steps[is.na(mergeddata$steps)] <- mergeddata$average[is.na(mergeddata$steps)]
mergeddata
The mean of the total number of steps taken per day is: **mean =`r format(mean(stepsperdayoptimised$steps),digits=2,nsmall=2)`** and the median is: **median= `r format(median(stepsperdayoptimised$steps),digits=2,nsmall=2)`**.
stepsperdayoptimised<-mergeddata%>%
group_by(date)%>%
summarise(steps=sum(steps))
hist(stepsperdayoptimised)
hist(stepsperdayoptimised$steps)
hist(stepsperdayoptimised$steps,binwidth=3000)
hist(stepsperday$steps)
hist(stepsperdayoptimised$steps)
hist(stepsperday$steps)
hist(stepsperdayoptimised$steps)
m+geom_histogram(colour = "darkred", fill = "orange",binwidth=3000)+
ylim(c(0, 25))+
stat_bin(binwidth=2000,geom="text", aes(label=..count..), vjust=-1.5)+
labs(x="Steps Per Day", y="No of days") +
scale_x_continuous(breaks=seq(0,24000,3000))
m<-ggplot(stepsperdayoptimised,aes(x=steps))
m+geom_histogram(colour = "darkred", fill = "orange",binwidth=2000)+
ylim(c(0, 25))+
stat_bin(binwidth=2000,geom="text", aes(label=..count..), vjust=-1.5)+
labs(x="Steps Per Day", y="No of days") +
scale_x_continuous(breaks=seq(0,24000,3000))
m<-ggplot(stepsperdayoptimised,aes(x=steps))
m+geom_histogram(colour = "darkred", fill = "orange",binwidth=2000)+
ylim(c(0, 25))+
stat_bin(binwidth=2000,geom="text", aes(label=..count..), vjust=-1.5)+
labs(x="Steps Per Day", y="No of days") +
scale_x_continuous(breaks=seq(0,24000,3000))
m<-ggplot(stepsperdayoptimised,aes(x=steps))
m+geom_histogram(colour = "darkred", fill = "orange",binwidth=2000)+
ylim(c(0, 30))+
stat_bin(binwidth=2000,geom="text", aes(label=..count..), vjust=-1.5)+
labs(x="Steps Per Day", y="No of days") +
scale_x_continuous(breaks=seq(0,24000,3000))
m<-ggplot(stepsperdayoptimised,aes(x=steps))
m+geom_histogram(colour = "darkred", fill = "orange",binwidth=2000)+
ylim(c(0, 30))+
stat_bin(binwidth=2000,geom="text", aes(label=..count..), vjust=-1.5)+
labs(x="Steps Per Day", y="No of days") +
scale_x_continuous(breaks=seq(0,24000,2000))
m<-ggplot(stepsperday,aes(x=steps))
m+geom_histogram(colour = "darkgreen", fill = "green",binwidth=2000)+
ylim(c(0, 20))+
stat_bin(binwidth=2000,geom="text", aes(label=..count..), vjust=-1.5)+
labs(x="Steps Per Day", y="No of days") +
scale_x_continuous(breaks=seq(0,24000,2000))
stepsperdayoptimised$theday<-weekdays(stepsperdayoptimised$date)
head(stepsperdayoptimised)
stepsperdayoptimised$theday<-as.factor(weekdays(stepsperdayoptimised$date))
stepsperdayoptimised$theweekend<-"weekday"
head(stepsperdayoptimised)
stepsperdayoptimised$theweekend[stepsperdayoptimised$theweekend=="Saturday"|stepsperdayoptimised$theweekend=="Sunday"] <- "weekend"
head(stepsperdayoptimised)
stepsperdayoptimised$theweekend[stepsperdayoptimised$theday=="Saturday"|stepsperdayoptimised$theday=="Sunday"] <- "weekend"
head(stepsperdayoptimised)
head(stepsperdayoptimised,20)
m3<-ggplot(stepsperdayoptimised,aes(x=interval,y=steps))
m3+geom_line(colour = "darkblue")+
labs(x="Interval", y="Number of steps")
stepsperintervaloptimised<-mergeddata%>%
group_by(interval)%>%
summarise(steps=mean(steps))
head(stepsperintervaloptimised)
home(mergeddata)
head(mergeddata)
mergeddata$theday<-as.factor(weekdays(mergeddata$date))
mergeddata$theweekend<-"weekday"
mergeddata$theweekend[mergeddata$theday=="Saturday"|mergeddata$theday=="Sunday"] <- "weekend"
head(mergeddata)
stepsperintervaloptimised<-mergeddata%>%
group_by(interval)%>%
summarise(steps=mean(steps))
m3<-ggplot(stepsperintervaloptimised,aes(x=interval,y=steps))
m3+geom_line(colour = "darkblue")+
labs(x="Interval", y="Number of steps")
m3<-ggplot(stepsperintervaloptimised,aes(x=interval,y=steps))
m3+geom_line(colour = "darkblue")+
labs(x="Interval", y="Number of steps")+
facet_grid(theweekend~.)
head(stepsperintervaloptimised)
stepsperintervaloptimised<-mergeddata%>%
group_by(interval,theweekend)%>%
summarise(steps=mean(steps))
head(stepsperintervaloptimised)
m3<-ggplot(stepsperintervaloptimised,aes(x=interval,y=steps))
m3+geom_line(colour = "darkblue")+
labs(x="Interval", y="Number of steps")+
facet_grid(theweekend~.)
knit2html()
install.packages("knit2html")
knitr2html()
knit2html()
knit2html("PA1_template.Rmd","test.html")
install.packages("knitr")
knit2html()
knit2html
?knit2html
??knit2html
knit2html("test.Rmd")
install.packages("knitr")
knit2html("test.Rmd")
install.packages("knit2html")
knit2html("test.Rmd")
